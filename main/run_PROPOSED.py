import os
import sys
import time

import numpy as np
import rich
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
import torch.nn as nn

sys.path.append("./")
from configs import ProposedConfig
from datasets.cifar import CIFAR, load_CIFAR
from datasets.imagenet import load_imagenet
from datasets.svhn import SVHN, Selcted_DATA_Proposed, load_SVHN
from datasets.tiny import TinyImageNet, load_tiny
from datasets.transforms import SemiAugment, TestAugment
from models import WRN, ResNet50, ViT, densenet121
from tasks.classification_Proposed import Classification
from utils.gpu import set_gpu
from utils.logging import get_rich_logger
from utils.wandb import configure_wandb
# 기존 import 아래에 추가
from datasets.ptbxl import get_ptbxl
from models.resnet1d import ResNet1D


NUM_CLASSES = {
    "cifar10": 6,
    "cifar100": 50,
    "svhn": 6,
    "tiny": 100,
    "imagenet": 500,
    "ptbxl": 3,  # NORM, MI, CD (3개 클래스)
}

AUGMENTS = {"semi": SemiAugment, "test": TestAugment}


def main():
    """Main function for single/distributed linear classification."""

    config = ProposedConfig.parse_arguments()
    set_gpu(config)
    num_gpus_per_node = len(config.gpus)
    world_size = config.num_nodes * num_gpus_per_node
    distributed = world_size > 1
    setattr(config, "num_gpus_per_node", num_gpus_per_node)
    setattr(config, "world_size", world_size)
    setattr(config, "distributed", distributed)

    rich.print(config.__dict__)
    config.save()

    np.random.seed(config.seed)
    torch.manual_seed(config.seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

    if config.distributed:
        rich.print(f"Distributed training on {world_size} GPUs.")
        mp.spawn(main_worker, nprocs=config.num_gpus_per_node, args=(config,))
    else:
        rich.print("Single GPU training.")
        main_worker(0, config=config)  # single machine, single gpu


def main_worker(local_rank: int, config: object):
    """Single process."""

    torch.cuda.set_device(local_rank)
    if config.distributed:
        dist_rank = config.node_rank * config.num_gpus_per_node + local_rank
        dist.init_process_group(
            backend=config.dist_backend,
            init_method=config.dist_url,
            world_size=config.world_size,
            rank=dist_rank,
        )

    config.batch_size = config.batch_size // config.world_size
    config.num_workers = config.num_workers // config.num_gpus_per_node

    num_classes = NUM_CLASSES[config.data]

    # Networks
    if config.backbone_type in ["wide28_10", "wide28_2"]:
        model = WRN(
            width=int(config.backbone_type.split("_")[-1]),
            num_classes=num_classes,
            normalize=config.normalize,
        )
    elif config.backbone_type == "resnet50":
        model = ResNet50(num_classes=num_classes, normalize=config.normalize)
    elif config.backbone_type == "vit":
        model = ViT(num_classes=num_classes, normalize=config.normalize)
    elif config.backbone_type == "densenet121":
        model = densenet121(num_class=num_classes, normalize=config.normalize)
    # [추가] 1D 모델 연결
    elif config.backbone_type == "resnet1d":
        model = ResNet1D(num_classes=num_classes, normalize=config.normalize)
    else:
        raise NotImplementedError

    # create logger
    if local_rank == 0:
        logfile = os.path.join(config.checkpoint_dir, "main.log")
        logger = get_rich_logger(logfile=logfile)
        if config.enable_wandb:
            configure_wandb(
                name=f"{config.task} : {config.hash}",
                project=f"SafeSSL-Calibration-{config.data}-{config.task}{config.wandb_proj_v}",
                config=config,
            )
    else:
        logger = None

    # Sub-Network Plus
    setattr(model, "cali_scaler", nn.Parameter(torch.ones(1) * 1.5))
    setattr(model, "ova_cali_scaler", nn.Parameter(torch.ones(1) * 1.5))
    setattr(
        model,
        "ova_classifiers",
        nn.Linear(model.in_features, int(model.class_num * 2), bias=False),
    )

    # Data (transforms & datasets)
    trans_kwargs = dict(
        size=config.input_size, data=config.data, impl=config.augmentation
    )
    train_trans = AUGMENTS[config.train_augment](**trans_kwargs)
    test_trans = AUGMENTS[config.test_augment](**trans_kwargs)

    if config.data in ["cifar10", "cifar100"]:

        datasets, _ = load_CIFAR(
            root=config.root,
            data_name=config.data,
            n_valid_per_class=config.n_valid_per_class,
            seed=config.seed,
            n_label_per_class=config.n_label_per_class,
            mismatch_ratio=config.mismatch_ratio,
            input_size=config.input_size,
            logger=logger,
        )

        labeled_set = Selcted_DATA_Proposed(
            dataset=datasets["l_train"], transform=train_trans, name="train_lb"
        )
        unlabeled_set = Selcted_DATA_Proposed(
            dataset=datasets["u_train"], name="train_ulb", transform=train_trans
        )

        eval_set = CIFAR(
            data_name=config.data, dataset=datasets["validation"], transform=test_trans
        )
        test_set = CIFAR(
            data_name=config.data, dataset=datasets["test"], transform=test_trans
        )
        open_test_set = CIFAR(
            data_name=config.data, dataset=datasets["test_total"], transform=test_trans
        )
    # [추가] PTB-XL 데이터셋 연결
    elif config.data == "ptbxl":
        # PTB-XL은 별도의 Augmentation이 아직 없으므로 transform=None으로 둡니다.
        # (추후 datasets/ptbxl.py 안에 Augmentation 로직을 넣으면 됩니다)
        
        train_labeled_dataset, train_unlabeled_dataset, val_dataset, test_dataset = get_ptbxl(config, root=config.root)
        
        # CaliMatch는 'Selcted_DATA_Proposed'라는 래퍼(Wrapper)를 씌워야 하지만,
        # get_ptbxl에서 이미 잘 나눠서 리턴했으므로 그대로 변수에 할당합니다.
        labeled_set = train_labeled_dataset
        unlabeled_set = train_unlabeled_dataset
        eval_set = val_dataset
        test_set = test_dataset
        open_test_set = test_dataset # OOD 평가용 (일단 test와 동일하게 설정)

        # [⭐⭐ 여기 추가 ⭐⭐] 로깅 에러 방지용 datasets 변수 생성
        datasets = {
            'l_train': {'labels': train_labeled_dataset.labels},
            'u_train': {'labels': train_unlabeled_dataset.labels}
        }

    elif config.data == "tiny":

        datasets, _ = load_tiny(
            root=config.root,
            n_label_per_class=config.n_label_per_class,
            n_valid_per_class=config.n_valid_per_class,
            mismatch_ratio=config.mismatch_ratio,
            random_state=config.seed,
            logger=logger,
        )

        labeled_set = Selcted_DATA_Proposed(
            dataset=datasets["l_train"], transform=train_trans, name="train_lb"
        )
        unlabeled_set = Selcted_DATA_Proposed(
            dataset=datasets["u_train"], name="train_ulb", transform=train_trans
        )

        eval_set = TinyImageNet(
            data_name=config.data, dataset=datasets["validation"], transform=test_trans
        )
        test_set = TinyImageNet(
            data_name=config.data, dataset=datasets["test"], transform=test_trans
        )
        open_test_set = TinyImageNet(
            data_name=config.data, dataset=datasets["test_total"], transform=test_trans
        )

    elif config.data == "svhn":

        datasets, _ = load_SVHN(
            root=config.root,
            data_name=config.data,
            n_label_per_class=config.n_label_per_class,
            mismatch_ratio=config.mismatch_ratio,
            random_state=config.seed,
            logger=logger,
        )

        labeled_set = Selcted_DATA_Proposed(
            data_name=config.data,
            dataset=datasets["l_train"],
            name="train_lb",
            transform=train_trans,
        )
        unlabeled_set = Selcted_DATA_Proposed(
            data_name=config.data,
            dataset=datasets["u_train"],
            name="train_ulb",
            transform=train_trans,
        )

        eval_set = SVHN(
            data_name=config.data, dataset=datasets["validation"], transform=test_trans
        )
        test_set = SVHN(
            data_name=config.data, dataset=datasets["test"], transform=test_trans
        )
        open_test_set = SVHN(
            data_name=config.data, dataset=datasets["test_total"], transform=test_trans
        )

    elif config.data == "imagenet":

        datasets, _, trainset, testset = load_imagenet(
            root=config.root,
            n_label_per_class=config.n_label_per_class,
            mismatch_ratio=config.mismatch_ratio,
            random_state=config.seed,
            logger=logger,
        )

        from ffcv.fields import IntField, RGBImageField
        from ffcv.writer import DatasetWriter
        from torch.utils.data import Subset

        for mode in ["l_train", "u_train", "validation"]:
            ffcv_file_path = os.path.join(
                config.root, "full-imagenet", "train", f"{mode}.ffcv"
            )
            if not os.path.exists(ffcv_file_path):
                writer = DatasetWriter(
                    ffcv_file_path,
                    {
                        "image": RGBImageField(
                            write_mode="proportion",
                            max_resolution=500,
                            compress_probability=0.5,
                            jpeg_quality=90,
                        ),
                        "label": IntField(),
                    },
                    num_workers=config.num_workers,
                )
                writer.from_indexed_dataset(
                    Subset(trainset, datasets[mode]["images"]), chunksize=100
                )

        for mode in ["test", "test_total"]:
            ffcv_file_path = os.path.join(
                config.root, "full-imagenet", "val", f"{mode}.ffcv"
            )
            if not os.path.exists(ffcv_file_path):
                writer = DatasetWriter(
                    ffcv_file_path,
                    {
                        "image": RGBImageField(
                            write_mode="proportion",
                            max_resolution=500,
                            compress_probability=0.5,
                            jpeg_quality=90,
                        ),
                        "label": IntField(),
                    },
                    num_workers=config.num_workers,
                )
                writer.from_indexed_dataset(
                    Subset(testset, datasets[mode]["images"]), chunksize=100
                )

        labeled_set = os.path.join(
            config.root, "full-imagenet", "train", "l_train.ffcv"
        )
        unlabeled_set = os.path.join(
            config.root, "full-imagenet", "train", "u_train.ffcv"
        )
        eval_set = os.path.join(
            config.root, "full-imagenet", "train", "validation.ffcv"
        )
        test_set = os.path.join(config.root, "full-imagenet", "val", "test.ffcv")
        open_test_set = os.path.join(
            config.root, "full-imagenet", "val", "test_total.ffcv"
        )

        from tasks.classification_Proposed import ImageNetClassification

    else:
        raise NotImplementedError

    if local_rank == 0:
        logger.info(f"Data: {config.data}")
        logger.info(
            f"Labeled Data Observations: {len(datasets['l_train']['labels']):,}"
        )
        logger.info(
            f"Unlabeled Data Observations: {len(datasets['u_train']['labels']):,}"
        )
        logger.info(f"Backbone: {config.backbone_type}")
        logger.info(f"Checkpoint directory: {config.checkpoint_dir}")

    # Model (Task)
    model = (
        Classification(backbone=model)
        if config.data != "imagenet"
        else ImageNetClassification(backbone=model)
    )
    model.prepare(
        ckpt_dir=config.checkpoint_dir,
        optimizer=config.optimizer,
        learning_rate=config.learning_rate,
        iterations=config.iterations,
        batch_size=config.batch_size,
        num_workers=config.num_workers,
        local_rank=local_rank,
        mixed_precision=config.mixed_precision,
        gamma=config.gamma,
        milestones=config.milestones,
        weight_decay=config.weight_decay,
    )

    # Train & evaluate
    start = time.time()
    model.run(
        train_set=[labeled_set, unlabeled_set],
        eval_set=eval_set,
        test_set=test_set,
        open_test_set=open_test_set,
        save_every=config.save_every,
        tau=config.tau,
        pi=config.pi,
        lambda_cali=config.lambda_cali,
        lambda_ova_soft=config.lambda_ova_soft,
        lambda_ova_cali=config.lambda_ova_cali,
        lambda_ova=config.lambda_ova,
        lambda_fix=config.lambda_fix,
        start_fix=config.start_fix,
        n_bins=config.n_bins,
        train_n_bins=config.train_n_bins,
        distributed=config.distributed,
        enable_plot=config.enable_plot,
        warm_up_end=config.warm_up,
        logger=logger,
    )
    elapsed_sec = time.time() - start

    if logger is not None:
        elapsed_mins = elapsed_sec / 60
        logger.info(f"Total training time: {elapsed_mins:,.2f} minutes.")
        logger.handlers.clear()


if __name__ == "__main__":

    try:
        main()
    except KeyboardInterrupt:
        sys.exit(0)
